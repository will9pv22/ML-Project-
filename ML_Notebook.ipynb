{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO TIME SERIES ORDER SERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datos y disponibilidad de datos en fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = './data/orders_orders.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ver rango de fechas\n",
    "print(\"Rango de fechas:\", df['Order Date'].min(), \"a\", df['Order Date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumar cifra diaria y escoger las columnas que utilizaremos para el timeseries modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación de los dos datasets (train y test) por los años 2011-2013 para el train y 2014 para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que las fechas estén ordenadas\n",
    "data = data.sort_values('Order Date')\n",
    "\n",
    "# Agregar ventas diarias\n",
    "daily_sales = data.groupby('Order Date')['Sales'].sum().reset_index()\n",
    "\n",
    "# Dividir en train y test\n",
    "train = daily_sales[(daily_sales['Order Date'] >= '2011-01-01') & (daily_sales['Order Date'] <= '2013-12-31')]\n",
    "test = daily_sales[(daily_sales['Order Date'] >= '2014-01-01') & (daily_sales['Order Date'] <= '2014-12-31')]\n",
    "\n",
    "print(\"Train:\", train['Order Date'].min(), \"a\", train['Order Date'].max())\n",
    "print(\"Test:\", test['Order Date'].min(), \"a\", test['Order Date'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploracion visual de los datos (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Configuración de índice temporal\n",
    "train.set_index('Order Date', inplace=True)\n",
    "\n",
    "# Descomposición de la serie\n",
    "decompose_result = seasonal_decompose(train['Sales'], model='additive', period=365)\n",
    "\n",
    "# Gráficos de descomposición\n",
    "decompose_result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualización adicional de la tendencia\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train['Sales'], label='Ventas Diarias')\n",
    "plt.plot(decompose_result.trend, label='Tendencia', color='orange')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de test AdFuller o ADF para detectar estacionalidad en los datos tanto de train como de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(series, title=\"\"):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'{title} ADF Test Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:', result[4])\n",
    "\n",
    "# Prueba para train y test\n",
    "test_stationarity(train['Sales'], \"Train\")\n",
    "test_stationarity(test.set_index('Order Date')['Sales'], \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos los datos de test viendo los resultados que no son estacionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Sales_diff'] = test['Sales'] - test['Sales'].shift(1)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "test_stationarity(test['Sales_diff'].dropna(), \"Test Diferenciado\")\n",
    "train['Sales_diff'] = train['Sales'] - train['Sales'].shift(1)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "test_stationarity(train['Sales_diff'].dropna(), \"Train Diferenciado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lanzamos los modelos a entrenar en el día a día. Usaremos SARIMA y ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Modelo ARIMA en datos diferenciados de Train\n",
    "arima_model = ARIMA(train['Sales_diff'].dropna(), order=(1, 1, 1)).fit()\n",
    "\n",
    "# Predicciones en Test (diferenciado)\n",
    "arima_forecast_diff = arima_model.forecast(steps=len(test['Sales_diff'].dropna()))\n",
    "\n",
    "# Reintegración de las predicciones a la escala original\n",
    "arima_forecast = arima_forecast_diff.cumsum() + train['Sales'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Modelo SARIMA en datos diferenciados de Train\n",
    "sarima_model = SARIMAX(train['Sales_diff'].dropna(), \n",
    "                       order=(1, 1, 1), \n",
    "                       seasonal_order=(1, 1, 1, 365)).fit()\n",
    "\n",
    "# Predicciones en Test (diferenciado)\n",
    "sarima_forecast_diff = sarima_model.forecast(steps=len(test['Sales_diff'].dropna()))\n",
    "\n",
    "# Reintegración de las predicciones a la escala original\n",
    "sarima_forecast = sarima_forecast_diff.cumsum() + train['Sales'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el funcionamiento del modelo  con las diferentes métricas de RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Evaluación para ARIMA\n",
    "arima_rmse = np.sqrt(mean_squared_error(test['Sales'], arima_forecast))\n",
    "arima_mae = mean_absolute_error(test['Sales'], arima_forecast)\n",
    "\n",
    "# Evaluación para SARIMA\n",
    "sarima_rmse = np.sqrt(mean_squared_error(test['Sales'], sarima_forecast))\n",
    "sarima_mae = mean_absolute_error(test['Sales'], sarima_forecast)\n",
    "\n",
    "print(\"ARIMA - RMSE:\", arima_rmse, \"MAE:\", arima_mae)\n",
    "print(\"SARIMA - RMSE:\", sarima_rmse, \"MAE:\", sarima_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planteamos la predicción de 2015 y la enfrentamos a los datos de 2014 tanto reales como predecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones para 2015 (365 días)\n",
    "sarima_2015_forecast_diff = sarima_model.get_forecast(steps=365).predicted_mean\n",
    "\n",
    "# Reintegrar predicciones a la escala original\n",
    "sarima_2015_forecast = sarima_2015_forecast_diff.cumsum() + train['Sales'].iloc[-1]\n",
    "\n",
    "# Visualización de las predicciones\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test['Order Date'], test['Sales'], label='Datos Reales (2014)')\n",
    "plt.plot(test['Order Date'], sarima_forecast, label='Predicciones (2014)')\n",
    "plt.plot(pd.date_range('2015-01-01', periods=365), sarima_2015_forecast, label='Predicciones (2015)', color='orange')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos la mejora de los parámetros con pdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# GridSearch para SARIMA\n",
    "auto_model = auto_arima(train['Sales_diff'].dropna(), \n",
    "                        seasonal=True, m=365, \n",
    "                        trace=True, error_action='ignore', \n",
    "                        suppress_warnings=True, stepwise=True)\n",
    "\n",
    "print(\"Mejores parámetros SARIMA:\")\n",
    "print(\"Order:\", auto_model.order)\n",
    "print(\"Seasonal Order:\", auto_model.seasonal_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reentrenamos el modelo con los parámetros sacados del pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain con los mejores parámetros encontrados\n",
    "best_sarima_model = SARIMAX(train['Sales_diff'].dropna(),\n",
    "                            order=auto_model.order, \n",
    "                            seasonal_order=auto_model.seasonal_order).fit()\n",
    "\n",
    "# Predicciones en Test\n",
    "best_sarima_forecast_diff = best_sarima_model.forecast(steps=len(test['Sales_diff'].dropna()))\n",
    "best_sarima_forecast = best_sarima_forecast_diff.cumsum() + train['Sales'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a reevaluar el modelo SARIMA para ver si han mejorado las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo optimizado\n",
    "best_sarima_rmse = np.sqrt(mean_squared_error(test['Sales'], best_sarima_forecast))\n",
    "best_sarima_mae = mean_absolute_error(test['Sales'], best_sarima_forecast)\n",
    "\n",
    "print(\"SARIMA Optimizado - RMSE:\", best_sarima_rmse, \"MAE:\", best_sarima_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez aquí, planteamos un cambio en el modelado y volvemos a hacer los mismos pasos pero de forma semanal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = './data/orders_orders.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ver rango de fechas\n",
    "print(\"Rango de fechas:\", df['Order Date'].min(), \"a\", df['Order Date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui hacemos el sumatorio semanal y nos aseguramos sobre todo que haya el mismo numero de semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar la columna 'Week' basada en la fecha\n",
    "df['Year'] = df['Order Date'].dt.year\n",
    "df['Week'] = df['Order Date'].dt.isocalendar().week\n",
    "\n",
    "# Resumir las ventas por semana\n",
    "df_weekly = df.groupby(['Year', 'Week'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Separar en train (2011-2013) y test (2014)\n",
    "train = df_weekly[df_weekly['Year'] < 2014]\n",
    "test = df_weekly[df_weekly['Year'] == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista con todas las combinaciones de año y semana\n",
    "all_weeks = [(year, week) for year in range(2011, 2015) for week in range(1, 53)]\n",
    "\n",
    "# Crear un DataFrame con todas las combinaciones posibles de año y semana\n",
    "weeks_df = pd.DataFrame(all_weeks, columns=['Year', 'Week'])\n",
    "\n",
    "# Unir con los datos agregados, completando los valores faltantes\n",
    "df_weekly_full = pd.merge(weeks_df, df_weekly, on=['Year', 'Week'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofrecemos la visualización de los datos ahora ya partidos de forma semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Crear la columna 'Date' con el primer día de cada semana\n",
    "# Para esto, concatenamos el año y la semana y usamos pd.to_datetime con formato adecuado\n",
    "df_weekly_full['Date'] = pd.to_datetime(df_weekly_full['Year'].astype(str) + df_weekly_full['Week'].astype(str) + '1', format='%Y%W%w')\n",
    "\n",
    "# Establecer 'Date' como índice\n",
    "df_weekly_full.set_index('Date', inplace=True)\n",
    "\n",
    "# Descomposición de la serie temporal (estacionalidad, tendencia)\n",
    "decomposition = sm.tsa.seasonal_decompose(df_weekly_full['Sales'], model='additive', period=52)\n",
    "decomposition.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualización de la serie temporal completa\n",
    "df_weekly_full['Sales'].plot(figsize=(10,6))\n",
    "plt.title(\"Ventas Semanales\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Ventas\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lanzamos ahora de nuevo el test de ADF ya sabiendo que como los datos de 2014 pueden salir no estacionarios los diferenciamos para que ambos sean estacionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Función para comprobar estacionariedad\n",
    "def check_stationarity(series):\n",
    "    result = adfuller(series)\n",
    "    return result[0], result[1]\n",
    "\n",
    "# Realizar diferenciación si es necesario y comprobar la estacionariedad\n",
    "# Differenciación de primer orden para entrenamiento\n",
    "train_diff = train['Sales'].diff().dropna()\n",
    "\n",
    "# Test ADF para el conjunto de train después de diferenciación\n",
    "adf_train = check_stationarity(train_diff)\n",
    "print(f\"ADF Test Train (diferenciado): estadístico={adf_train[0]}, p-valor={adf_train[1]}\")\n",
    "\n",
    "# Differenciación de primer orden para test\n",
    "test_diff = test['Sales'].diff().dropna()\n",
    "\n",
    "# Test ADF para el conjunto de test después de diferenciación\n",
    "adf_test = check_stationarity(test_diff)\n",
    "print(f\"ADF Test Test (diferenciado): estadístico={adf_test[0]}, p-valor={adf_test[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos ahora los modelos pero ya con el formato de cifra semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Función para comprobar estacionariedad\n",
    "def check_stationarity(series):\n",
    "    result = adfuller(series)\n",
    "    return result[0], result[1]\n",
    "\n",
    "# Realizar diferenciación si es necesario y comprobar la estacionariedad\n",
    "# Differenciación de primer orden para entrenamiento\n",
    "train_diff = train['Sales'].diff().dropna()\n",
    "\n",
    "# Test ADF para el conjunto de train después de diferenciación\n",
    "adf_train = check_stationarity(train_diff)\n",
    "print(f\"ADF Test Train (diferenciado): estadístico={adf_train[0]}, p-valor={adf_train[1]}\")\n",
    "\n",
    "# Differenciación de primer orden para test\n",
    "test_diff = test['Sales'].diff().dropna()\n",
    "\n",
    "# Test ADF para el conjunto de test después de diferenciación\n",
    "adf_test = check_stationarity(test_diff)\n",
    "print(f\"ADF Test Test (diferenciado): estadístico={adf_test[0]}, p-valor={adf_test[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos los resultados que nos da el modelo con las métricas de error RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# RMSE y MAE para ARIMA\n",
    "rmse_arima = np.sqrt(mean_squared_error(test['Sales'], pred_arima))\n",
    "mae_arima = mean_absolute_error(test['Sales'], pred_arima)\n",
    "\n",
    "# RMSE y MAE para SARIMA\n",
    "rmse_sarima = np.sqrt(mean_squared_error(test['Sales'], pred_sarima))\n",
    "mae_sarima = mean_absolute_error(test['Sales'], pred_sarima)\n",
    "\n",
    "print(f\"ARIMA RMSE: {rmse_arima}, MAE: {mae_arima}\")\n",
    "print(f\"SARIMA RMSE: {rmse_sarima}, MAE: {mae_sarima}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lanzamos predicción del año 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción para 2015 con el mejor modelo (por ejemplo, SARIMA)\n",
    "pred_2015 = model_sarima_fit.forecast(steps=52)  # Predicción para 52 semanas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos las diferentes curvas de ventaas semanales en 2014 real vs 2014 predecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurarnos de que las predicciones están alineadas con las fechas del conjunto de prueba\n",
    "pred_arima.index = test.index\n",
    "pred_sarima.index = test.index\n",
    "\n",
    "# Gráfico de comparación\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Ventas reales\n",
    "plt.plot(test.index, test['Sales'], label='Ventas Reales (2014)', color='blue')\n",
    "\n",
    "# Predicciones ARIMA\n",
    "plt.plot(test.index, pred_arima, label='Predicciones ARIMA', color='green', linestyle='--')\n",
    "\n",
    "# Predicciones SARIMA\n",
    "plt.plot(test.index, pred_sarima, label='Predicciones SARIMA', color='red', linestyle=':')\n",
    "\n",
    "# Detalles del gráfico\n",
    "plt.title(\"Comparación de Ventas Reales y Predicciones ARIMA/SARIMA\", fontsize=16)\n",
    "plt.xlabel(\"Fecha\", fontsize=14)\n",
    "plt.ylabel(\"Ventas Semanales\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos ver como predice los datos en 2015 visualmente vs 2014 real y el del modelo SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_2014 = pd.date_range(start='2014-01-01', end='2014-12-31', freq='W')\n",
    "date_range_2015 = pd.date_range(start='2015-01-01', end='2015-12-31', freq='W')  # Ajustar el rango de fechas\n",
    "\n",
    "# Asignar el índice de fechas al conjunto de predicciones de 2015\n",
    "test.index = date_range_2014\n",
    "pred_2015.index = date_range_2015\n",
    "# Gráfico de comparación\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Ventas reales (2014)\n",
    "plt.plot(test.index, test['Sales'], label='Ventas Reales (2014)', color='blue')\n",
    "\n",
    "# Predicciones ARIMA (2014)\n",
    "plt.plot(test.index, pred_arima, label='Predicciones ARIMA (2014)', color='green', linestyle='--')\n",
    "\n",
    "# Predicciones SARIMA (2014)\n",
    "plt.plot(test.index, pred_sarima, label='Predicciones SARIMA (2014)', color='red', linestyle=':')\n",
    "\n",
    "# Predicciones SARIMA (2015)\n",
    "plt.plot(pred_2015.index, pred_2015, label='Predicciones SARIMA (2015)', color='orange', linestyle='-.')\n",
    "\n",
    "# Detalles del gráfico\n",
    "plt.title(\"Comparación de Ventas Reales (2014), Predicciones ARIMA/SARIMA y Predicciones para 2015\", fontsize=16)\n",
    "plt.xlabel(\"Fecha\", fontsize=14)\n",
    "plt.ylabel(\"Ventas Semanales\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "\n",
    "# Ajustar el formato del eje x para mostrar 2014 y 2015\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos ver cuales son los mejores parámetros para el modelo semanal de SARIMA realizado más arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definir el espacio de parámetros\n",
    "p = d = q = range(0, 3)  # Orden para (p,d,q)\n",
    "P = D = Q = range(0, 2)  # Orden para (P,D,Q)\n",
    "seasonal_period = [52]  # Periodo estacional\n",
    "\n",
    "# Generar todas las combinaciones posibles de parámetros\n",
    "param_combinations = list(itertools.product(p, d, q))\n",
    "seasonal_combinations = list(itertools.product(P, D, Q, seasonal_period))\n",
    "\n",
    "# Inicializar variables para almacenar el mejor modelo\n",
    "best_aic = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "for param in param_combinations:\n",
    "    for seasonal_param in seasonal_combinations:\n",
    "        try:\n",
    "            # Entrenar el modelo SARIMAX con los parámetros actuales\n",
    "            model = SARIMAX(\n",
    "                train['Sales'],\n",
    "                order=param,\n",
    "                seasonal_order=seasonal_param,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            model_fit = model.fit(disp=False)\n",
    "            \n",
    "            # Evaluar el modelo usando AIC\n",
    "            if model_fit.aic < best_aic:\n",
    "                best_aic = model_fit.aic\n",
    "                best_params = (param, seasonal_param)\n",
    "                best_model = model_fit\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Imprimir los mejores parámetros encontrados\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor AIC:\", best_aic)\n",
    "\n",
    "# Predecir usando el mejor modelo\n",
    "pred = best_model.forecast(steps=len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a reentrenar el modelo de SARIMAX con los mejores parámetros conseguido arriba y visualizar el modelo como actua con las predicciones del test y del 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Limitar el conjunto de datos de 2011-2013 para el entrenamiento\n",
    "train_filtered = train[(train['Year'] >= 2011) & (train['Year'] <= 2013)]\n",
    "# Limitar el conjunto de datos de 2014-2015 para la prueba\n",
    "test_filtered = test[(test['Year'] >= 2014) & (test['Year'] <= 2015)]\n",
    "\n",
    "# Reentrenar el modelo SARIMAX con los mejores parámetros obtenidos\n",
    "best_param, best_seasonal_param = best_params  # Usar los mejores parámetros de la búsqueda anterior\n",
    "\n",
    "model_sarima_final = SARIMAX(\n",
    "    train_filtered['Sales'],\n",
    "    order=best_param,\n",
    "    seasonal_order=best_seasonal_param,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "model_sarima_fit_final = model_sarima_final.fit()\n",
    "\n",
    "# Predicciones para 2014 y 2015\n",
    "pred_sarima_final = model_sarima_fit_final.forecast(steps=len(test_filtered))\n",
    "\n",
    "# Evaluar el modelo con el RMSE o MAE\n",
    "rmse = np.sqrt(mean_squared_error(test_filtered['Sales'], pred_sarima_final))\n",
    "print(f'RMSE para los datos de 2014 y 2015: {rmse}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pintamos de nuevo el modelo como queda con 2014 real y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizar las predicciones vs los datos reales para 2014 y 2015\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_filtered.index, test_filtered['Sales'], label='Ventas reales', color='blue')\n",
    "plt.plot(test_filtered.index, pred_sarima_final, label='Predicciones SARIMAX', color='red', linestyle='--')\n",
    "plt.title('Comparación de Predicciones y Ventas Reales (2014-2015)')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Ventas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el dato de 2015 comparado con el 2014 real y predecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear el rango de fechas para 2014 y 2015 (semanal)\n",
    "date_range_2014 = pd.date_range(start='2014-01-01', end='2014-12-31', freq='W')\n",
    "date_range_2015 = pd.date_range(start='2015-01-01', end='2015-12-31', freq='W')\n",
    "\n",
    "# Asignar el índice de fechas al conjunto de predicciones de 2015\n",
    "test_filtered.index = date_range_2014\n",
    "pred_sarima_final.index = date_range_2015  # Asegurarse que las predicciones tienen el índice de 2015\n",
    "\n",
    "# Gráfico de comparación\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Ventas reales (2014 y 2015)\n",
    "plt.plot(test_filtered.index, test_filtered['Sales'], label='Ventas Reales (2014-2015)', color='blue')\n",
    "\n",
    "# Predicciones SARIMA (2014)\n",
    "plt.plot(test_filtered.index, pred_sarima_final[:len(test_filtered)], label='Predicciones SARIMA (2014)', color='red', linestyle=':')\n",
    "\n",
    "# Predicciones SARIMA (2015)\n",
    "plt.plot(pred_sarima_final.index, pred_sarima_final, label='Predicciones SARIMA (2015)', color='orange', linestyle='-.')\n",
    "\n",
    "# Detalles del gráfico\n",
    "plt.title(\"Comparación de Ventas Reales (2014-2015) y Predicciones SARIMA para 2014 y 2015\", fontsize=16)\n",
    "plt.xlabel(\"Fecha\", fontsize=14)\n",
    "plt.ylabel(\"Ventas Semanales\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "\n",
    "# Ajustar el formato del eje x para mostrar las fechas correctamente\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
